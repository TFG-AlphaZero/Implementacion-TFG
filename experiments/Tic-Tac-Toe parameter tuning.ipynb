{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sudden-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "if 'tfg' not in os.listdir():\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hundred-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfg.alphaZero import create_alphazero, parallel_play\n",
    "from tfg.alphaZeroAdapters import TicTacToeAdapter\n",
    "from tfg.util import enable_gpu\n",
    "from tfg.alphaZeroConfig import AlphaZeroConfig\n",
    "from tfg.strategies import Minimax\n",
    "from game.tictactoe import TicTacToe\n",
    "\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joint-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_gpu()\n",
    "\n",
    "game = TicTacToe()\n",
    "adapter = TicTacToeAdapter()\n",
    "\n",
    "minimax = Minimax(game)\n",
    "\n",
    "model_filename = 'models/TicTacToe_params.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "personalized-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr, reg, filters, c, alpha\n",
    "configs = [\n",
    "    (.01,  0.,     16, 1.,  1.),\n",
    "    (.001, 0.,     16, 1.,  1.),\n",
    "    (.001, 0.,     32, 1.,  1.),\n",
    "    \n",
    "    (.01,  .0001,  16, 1.,  1.),\n",
    "    (.001, .0001,  32, 1.,  1.),\n",
    "    \n",
    "    (.01,  0.,     32, 1.,  .5),\n",
    "    (.001, 0.,     32, 1.,  .5),\n",
    "    (.01,  .0001,  32, 1.,  .5),\n",
    "    (.001, .0001,  32, 1.,  .5),\n",
    "    \n",
    "    (.001, 0.,     32, 1.2, .5),\n",
    "    (.001, .0001,  32, 1.2, .5),\n",
    "    \n",
    "    (.001, 0.,     32, .8,  .5),\n",
    "    (.001, .0001,  32, .8,  .5),\n",
    "    \n",
    "    (.001, .0001,  64, 1.,  .5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "economic-settlement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-15 11:49:00,066\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 - 3s - loss: 1.4160 - value_head_loss: 0.5784 - policy_head_loss: 2.2537\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2948 - value_head_loss: 0.4618 - policy_head_loss: 2.1278\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2418 - value_head_loss: 0.4093 - policy_head_loss: 2.0743\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.2133 - value_head_loss: 0.4018 - policy_head_loss: 2.0249\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1623 - value_head_loss: 0.3607 - policy_head_loss: 1.9639\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1803 - value_head_loss: 0.3989 - policy_head_loss: 1.9617\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.0329 - value_head_loss: 0.2903 - policy_head_loss: 1.7755\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 0.9373 - value_head_loss: 0.2647 - policy_head_loss: 1.6098\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 0.8760 - value_head_loss: 0.2454 - policy_head_loss: 1.5065\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.8335 - value_head_loss: 0.2261 - policy_head_loss: 1.4409\n",
      "Games played: 100\n",
      "Finished training after 38.41213893890381 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4786 - value_head_loss: 0.6109 - policy_head_loss: 2.3463\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.3045 - value_head_loss: 0.4027 - policy_head_loss: 2.2063\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2443 - value_head_loss: 0.3544 - policy_head_loss: 2.1341\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1996 - value_head_loss: 0.3106 - policy_head_loss: 2.0887\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1697 - value_head_loss: 0.2879 - policy_head_loss: 2.0515\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.2286 - value_head_loss: 0.3272 - policy_head_loss: 2.1301\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1906 - value_head_loss: 0.3060 - policy_head_loss: 2.0752\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.1437 - value_head_loss: 0.2640 - policy_head_loss: 2.0234\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1212 - value_head_loss: 0.2610 - policy_head_loss: 1.9814\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0908 - value_head_loss: 0.2347 - policy_head_loss: 1.9469\n",
      "Games played: 100\n",
      "Finished training after 28.874001502990723 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.3687 - value_head_loss: 0.4233 - policy_head_loss: 2.3141\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2048 - value_head_loss: 0.3183 - policy_head_loss: 2.0914\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.1481 - value_head_loss: 0.3067 - policy_head_loss: 1.9895\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1014 - value_head_loss: 0.2925 - policy_head_loss: 1.9103\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0539 - value_head_loss: 0.2744 - policy_head_loss: 1.8334\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.2667 - value_head_loss: 0.6031 - policy_head_loss: 1.9302\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1948 - value_head_loss: 0.5277 - policy_head_loss: 1.8619\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.1392 - value_head_loss: 0.4776 - policy_head_loss: 1.8007\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1152 - value_head_loss: 0.4730 - policy_head_loss: 1.7574\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0796 - value_head_loss: 0.4376 - policy_head_loss: 1.7215\n",
      "Games played: 100\n",
      "Finished training after 30.8536217212677 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4156 - value_head_loss: 0.5271 - policy_head_loss: 2.2895\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2853 - value_head_loss: 0.4392 - policy_head_loss: 2.1152\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2371 - value_head_loss: 0.4092 - policy_head_loss: 2.0479\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1843 - value_head_loss: 0.3863 - policy_head_loss: 1.9644\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1627 - value_head_loss: 0.4040 - policy_head_loss: 1.9026\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1888 - value_head_loss: 0.4483 - policy_head_loss: 1.9095\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.0784 - value_head_loss: 0.3735 - policy_head_loss: 1.7622\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0140 - value_head_loss: 0.3635 - policy_head_loss: 1.6423\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 0.9619 - value_head_loss: 0.3473 - policy_head_loss: 1.5533\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9196 - value_head_loss: 0.3297 - policy_head_loss: 1.4856\n",
      "Games played: 100\n",
      "Finished training after 29.195329427719116 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4288 - value_head_loss: 0.5537 - policy_head_loss: 2.2835\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2907 - value_head_loss: 0.4293 - policy_head_loss: 2.1316\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2397 - value_head_loss: 0.3921 - policy_head_loss: 2.0669\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1888 - value_head_loss: 0.3622 - policy_head_loss: 1.9949\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1415 - value_head_loss: 0.3565 - policy_head_loss: 1.9060\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.2421 - value_head_loss: 0.5211 - policy_head_loss: 1.9424\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1410 - value_head_loss: 0.4218 - policy_head_loss: 1.8395\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0783 - value_head_loss: 0.3792 - policy_head_loss: 1.7568\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0409 - value_head_loss: 0.3488 - policy_head_loss: 1.7122\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0132 - value_head_loss: 0.3349 - policy_head_loss: 1.6706\n",
      "Games played: 100\n",
      "Finished training after 30.66395854949951 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4433 - value_head_loss: 0.6764 - policy_head_loss: 2.2101\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2788 - value_head_loss: 0.5169 - policy_head_loss: 2.0406\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.1857 - value_head_loss: 0.4435 - policy_head_loss: 1.9279\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1214 - value_head_loss: 0.4036 - policy_head_loss: 1.8392\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0798 - value_head_loss: 0.3950 - policy_head_loss: 1.7646\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.0288 - value_head_loss: 0.3801 - policy_head_loss: 1.6776\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 0.8732 - value_head_loss: 0.2849 - policy_head_loss: 1.4616\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 0.8051 - value_head_loss: 0.2703 - policy_head_loss: 1.3400\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 0.7629 - value_head_loss: 0.2655 - policy_head_loss: 1.2604\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.7445 - value_head_loss: 0.2590 - policy_head_loss: 1.2300\n",
      "Games played: 100\n",
      "Finished training after 29.64478588104248 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4780 - value_head_loss: 0.6912 - policy_head_loss: 2.2648\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.3044 - value_head_loss: 0.5285 - policy_head_loss: 2.0803\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2445 - value_head_loss: 0.4816 - policy_head_loss: 2.0073\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1911 - value_head_loss: 0.4355 - policy_head_loss: 1.9466\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1463 - value_head_loss: 0.4077 - policy_head_loss: 1.8848\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1865 - value_head_loss: 0.4080 - policy_head_loss: 1.9650\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1174 - value_head_loss: 0.3635 - policy_head_loss: 1.8713\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0614 - value_head_loss: 0.3342 - policy_head_loss: 1.7886\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0224 - value_head_loss: 0.3154 - policy_head_loss: 1.7295\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9936 - value_head_loss: 0.3024 - policy_head_loss: 1.6847\n",
      "Games played: 100\n",
      "Finished training after 30.379223585128784 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4318 - value_head_loss: 0.5860 - policy_head_loss: 2.2539\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.3354 - value_head_loss: 0.5383 - policy_head_loss: 2.1024\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2959 - value_head_loss: 0.5129 - policy_head_loss: 2.0457\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.2514 - value_head_loss: 0.4758 - policy_head_loss: 1.9924\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1915 - value_head_loss: 0.4358 - policy_head_loss: 1.9116\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1825 - value_head_loss: 0.4325 - policy_head_loss: 1.8957\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.0957 - value_head_loss: 0.3646 - policy_head_loss: 1.7883\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0368 - value_head_loss: 0.3295 - policy_head_loss: 1.7041\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0165 - value_head_loss: 0.3300 - policy_head_loss: 1.6614\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9751 - value_head_loss: 0.3109 - policy_head_loss: 1.5957\n",
      "Games played: 100\n",
      "Finished training after 30.435019493103027 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4484 - value_head_loss: 0.5864 - policy_head_loss: 2.2904\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.3021 - value_head_loss: 0.4561 - policy_head_loss: 2.1280\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2461 - value_head_loss: 0.4188 - policy_head_loss: 2.0533\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1954 - value_head_loss: 0.3932 - policy_head_loss: 1.9776\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1509 - value_head_loss: 0.3761 - policy_head_loss: 1.9056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1981 - value_head_loss: 0.3983 - policy_head_loss: 1.9776\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1213 - value_head_loss: 0.3558 - policy_head_loss: 1.8665\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0728 - value_head_loss: 0.3227 - policy_head_loss: 1.8027\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0362 - value_head_loss: 0.3080 - policy_head_loss: 1.7440\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9954 - value_head_loss: 0.2797 - policy_head_loss: 1.6906\n",
      "Games played: 100\n",
      "Finished training after 31.071317195892334 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-15 11:56:32,357\tWARNING worker.py:1107 -- The log monitor on node DESKTOP-821E24O failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pirra\\Anaconda3\\envs\\AlphaZero\\lib\\site-packages\\ray\\log_monitor.py\", line 359, in <module>\n",
      "    log_monitor.run()\n",
      "  File \"C:\\Users\\pirra\\Anaconda3\\envs\\AlphaZero\\lib\\site-packages\\ray\\log_monitor.py\", line 280, in run\n",
      "    self.open_closed_files()\n",
      "  File \"C:\\Users\\pirra\\Anaconda3\\envs\\AlphaZero\\lib\\site-packages\\ray\\log_monitor.py\", line 167, in open_closed_files\n",
      "    self.close_all_files()\n",
      "  File \"C:\\Users\\pirra\\Anaconda3\\envs\\AlphaZero\\lib\\site-packages\\ray\\log_monitor.py\", line 102, in close_all_files\n",
      "    os.kill(file_info.worker_pid, 0)\n",
      "TypeError: an integer is required (got type str)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4170 - value_head_loss: 0.5894 - policy_head_loss: 2.2446\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2732 - value_head_loss: 0.4792 - policy_head_loss: 2.0672\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2206 - value_head_loss: 0.4314 - policy_head_loss: 2.0098\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1725 - value_head_loss: 0.3938 - policy_head_loss: 1.9511\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1317 - value_head_loss: 0.3513 - policy_head_loss: 1.9121\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1920 - value_head_loss: 0.3715 - policy_head_loss: 2.0126\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1202 - value_head_loss: 0.3336 - policy_head_loss: 1.9068\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0799 - value_head_loss: 0.3060 - policy_head_loss: 1.8538\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0473 - value_head_loss: 0.2827 - policy_head_loss: 1.8119\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0188 - value_head_loss: 0.2667 - policy_head_loss: 1.7708\n",
      "Games played: 100\n",
      "Finished training after 29.719826459884644 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4170 - value_head_loss: 0.5269 - policy_head_loss: 2.2875\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2596 - value_head_loss: 0.3936 - policy_head_loss: 2.1059\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2141 - value_head_loss: 0.3775 - policy_head_loss: 2.0310\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1679 - value_head_loss: 0.3527 - policy_head_loss: 1.9633\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1240 - value_head_loss: 0.3408 - policy_head_loss: 1.8874\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.2358 - value_head_loss: 0.4816 - policy_head_loss: 1.9702\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.1671 - value_head_loss: 0.4404 - policy_head_loss: 1.8739\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.1204 - value_head_loss: 0.4098 - policy_head_loss: 1.8111\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0876 - value_head_loss: 0.3837 - policy_head_loss: 1.7714\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0562 - value_head_loss: 0.3596 - policy_head_loss: 1.7326\n",
      "Games played: 100\n",
      "Finished training after 30.970491647720337 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4749 - value_head_loss: 0.6737 - policy_head_loss: 2.2761\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.3265 - value_head_loss: 0.5326 - policy_head_loss: 2.1205\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2730 - value_head_loss: 0.4922 - policy_head_loss: 2.0538\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.2215 - value_head_loss: 0.4552 - policy_head_loss: 1.9879\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1860 - value_head_loss: 0.4437 - policy_head_loss: 1.9282\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1750 - value_head_loss: 0.3546 - policy_head_loss: 1.9953\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.0907 - value_head_loss: 0.2975 - policy_head_loss: 1.8840\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0435 - value_head_loss: 0.2805 - policy_head_loss: 1.8065\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 0.9992 - value_head_loss: 0.2640 - policy_head_loss: 1.7344\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9562 - value_head_loss: 0.2440 - policy_head_loss: 1.6684\n",
      "Games played: 100\n",
      "Finished training after 29.045972108840942 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4325 - value_head_loss: 0.4949 - policy_head_loss: 2.3495\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.2661 - value_head_loss: 0.3810 - policy_head_loss: 2.1307\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2014 - value_head_loss: 0.3532 - policy_head_loss: 2.0290\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1386 - value_head_loss: 0.3253 - policy_head_loss: 1.9312\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.0865 - value_head_loss: 0.3118 - policy_head_loss: 1.8405\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1662 - value_head_loss: 0.4170 - policy_head_loss: 1.8945\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.0888 - value_head_loss: 0.3601 - policy_head_loss: 1.7967\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.0563 - value_head_loss: 0.3330 - policy_head_loss: 1.7586\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.0095 - value_head_loss: 0.3103 - policy_head_loss: 1.6877\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9788 - value_head_loss: 0.3012 - policy_head_loss: 1.6353\n",
      "Games played: 100\n",
      "Finished training after 31.462547779083252 seconds\n",
      "Epoch 1/5\n",
      "12/12 - 1s - loss: 1.4900 - value_head_loss: 0.6938 - policy_head_loss: 2.2529\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.3048 - value_head_loss: 0.4916 - policy_head_loss: 2.0845\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 1.2306 - value_head_loss: 0.4179 - policy_head_loss: 2.0096\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 1.1671 - value_head_loss: 0.3796 - policy_head_loss: 1.9207\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 1.1118 - value_head_loss: 0.3635 - policy_head_loss: 1.8261\n",
      "Games played: 50\n",
      "Epoch 1/5\n",
      "12/12 - 0s - loss: 1.1053 - value_head_loss: 0.2972 - policy_head_loss: 1.8794\n",
      "Epoch 2/5\n",
      "12/12 - 0s - loss: 1.0391 - value_head_loss: 0.2710 - policy_head_loss: 1.7730\n",
      "Epoch 3/5\n",
      "12/12 - 0s - loss: 0.9813 - value_head_loss: 0.2438 - policy_head_loss: 1.6844\n",
      "Epoch 4/5\n",
      "12/12 - 0s - loss: 0.9454 - value_head_loss: 0.2274 - policy_head_loss: 1.6289\n",
      "Epoch 5/5\n",
      "12/12 - 0s - loss: 0.9108 - value_head_loss: 0.2188 - policy_head_loss: 1.5682\n",
      "Games played: 100\n",
      "Finished training after 30.28494358062744 seconds\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for lr, reg, filters, c, alpha in configs:\n",
    "    \n",
    "    config = AlphaZeroConfig(\n",
    "        learning_rate=lr,\n",
    "        regularizer_constant=reg,\n",
    "        residual_layers=1,\n",
    "        filters=filters,\n",
    "        kernel_size=(3, 3)\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    alphazero = create_alphazero(game, adapter, max_workers=10, self_play_times=50,\n",
    "                                 max_games_counter=100, buffer_size=500,\n",
    "                                 batch_size=384, temperature=100, epochs=5, c_puct=c,\n",
    "                                 exploration_noise=(.25, alpha), mcts_iter=200, nn_config=config)\n",
    "    print(\"Finished training after\", time.time() - start, \"seconds\")\n",
    "\n",
    "    alphazero.save(model_filename)\n",
    "\n",
    "    _, d, _ = parallel_play(game, adapter, minimax, model_filename,\n",
    "                            'black', max_workers=10, mcts_iter=100, games=50)\n",
    "    results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "frozen-disease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>reg</th>\n",
       "      <th>filters</th>\n",
       "      <th>c</th>\n",
       "      <th>alpha</th>\n",
       "      <th>draws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr     reg  filters    c  alpha  draws\n",
       "0   0.010  0.0000       16  1.0    1.0     24\n",
       "1   0.001  0.0000       16  1.0    1.0     13\n",
       "2   0.001  0.0000       32  1.0    1.0     25\n",
       "3   0.010  0.0001       16  1.0    1.0     46\n",
       "4   0.001  0.0001       32  1.0    1.0     17\n",
       "5   0.010  0.0000       32  1.0    0.5     46\n",
       "6   0.001  0.0000       32  1.0    0.5     34\n",
       "7   0.010  0.0001       32  1.0    0.5     48\n",
       "8   0.001  0.0001       32  1.0    0.5     47\n",
       "9   0.001  0.0000       32  1.2    0.5     41\n",
       "10  0.001  0.0001       32  1.2    0.5     46\n",
       "11  0.001  0.0000       32  0.8    0.5     44\n",
       "12  0.001  0.0001       32  0.8    0.5     47\n",
       "13  0.001  0.0001       64  1.0    0.5     25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(configs, columns=['lr', 'reg', 'filters', 'c', 'alpha'])\n",
    "df['draws'] = results\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rotary-adoption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>reg</th>\n",
       "      <th>filters</th>\n",
       "      <th>c</th>\n",
       "      <th>alpha</th>\n",
       "      <th>draws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lr     reg  filters    c  alpha  draws\n",
       "7   0.010  0.0001       32  1.0    0.5     48\n",
       "8   0.001  0.0001       32  1.0    0.5     47\n",
       "12  0.001  0.0001       32  0.8    0.5     47\n",
       "3   0.010  0.0001       16  1.0    1.0     46\n",
       "5   0.010  0.0000       32  1.0    0.5     46\n",
       "10  0.001  0.0001       32  1.2    0.5     46\n",
       "11  0.001  0.0000       32  0.8    0.5     44\n",
       "9   0.001  0.0000       32  1.2    0.5     41\n",
       "6   0.001  0.0000       32  1.0    0.5     34\n",
       "2   0.001  0.0000       32  1.0    1.0     25\n",
       "13  0.001  0.0001       64  1.0    0.5     25\n",
       "0   0.010  0.0000       16  1.0    1.0     24\n",
       "4   0.001  0.0001       32  1.0    1.0     17\n",
       "1   0.001  0.0000       16  1.0    1.0     13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('draws', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AlphaZero",
   "language": "python",
   "name": "alphazero"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
